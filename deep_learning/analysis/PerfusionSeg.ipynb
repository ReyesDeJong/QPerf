{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfusion mapping analysis using deep learning\n",
    "**Author**: `Hui Xue <hui.xue@nih.gov>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='1,2'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.onnx\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import *\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "animation.rcParams['animation.writer'] = 'ffmpeg'\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "import scipy\n",
    "import scipy as sp\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from IPython.display import display, clear_output, HTML, Image\n",
    "\n",
    "from PIL import Image\n",
    "import imp\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import sklearn\n",
    "import logging\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "#print(os.getcwd())\n",
    "#os.mkdir('./DebugOutput')\n",
    "\n",
    "def save_as_image(a, img_name='test', img_dir='./DebugOutput'):\n",
    "    N, C, H, W = a.shape\n",
    "    \n",
    "    a = np.transpose(a, (2, 3, 1, 0))\n",
    "    \n",
    "    for n in range(N):\n",
    "        filename = os.path.join(img_dir, img_name + str(n) + '.tif')\n",
    "        if C==3:\n",
    "            plt.imsave(filename, a[:,:,:,n])\n",
    "            continue\n",
    "        if C==1:\n",
    "            plt.imsave(filename, a[:,:,0,n])\n",
    "            continue\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "import training\n",
    "import models\n",
    "import hyper_search\n",
    "import plot_run\n",
    "import utils\n",
    "import utils.cmr_ml_utils_data\n",
    "import utils.cmr_ml_utils_plotting\n",
    "\n",
    "# dir(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = ['/mnt/disk1/TrainingData/Perf_SAX_SEG', '/mnt/disk1/TrainingData/Perf_SAX_SEG_Set2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFlip1stDim(object):\n",
    "    \"\"\"Randomly flip the first dimension of numpy array.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([N RO E1 ... ]): Image to be flipped.\n",
    "        Returns:\n",
    "            res: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        #print(img[0].shape)\n",
    "        #print(img[1].shape)\n",
    "            \n",
    "        if random.random() < self.p: \n",
    "                                \n",
    "            a = np.transpose(img[0], [1, 2, 0])\n",
    "            a = np.flipud(a)\n",
    "            a = np.transpose(a, [2, 0, 1])\n",
    "            \n",
    "            b = np.transpose(img[1], [1, 2, 0])\n",
    "            b = np.flipud(b)\n",
    "            b = np.transpose(b, [2, 0, 1])\n",
    "            return ( a.copy(), b.copy(), img[2] )\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "    \n",
    "class RandomFlip2ndDim(object):\n",
    "    \"\"\"Randomly flip the second dimension of numpy array.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([N RO E1 ... ]): Image to be flipped.\n",
    "        Returns:\n",
    "            res: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:    \n",
    "            a = np.transpose(img[0], [1, 2, 0])\n",
    "            a = np.fliplr(a)\n",
    "            a = np.transpose(a, [2, 0, 1])\n",
    "            \n",
    "            b = np.transpose(img[1], [1, 2, 0])\n",
    "            b = np.fliplr(b)\n",
    "            b = np.transpose(b, [2, 0, 1])\n",
    "            return ( a.copy(), b.copy(), img[2] )\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "    \n",
    "class RandomPermute2DT(object):\n",
    "    \"\"\"Randomly permute 1st and 2nd dimensions of numpy array.\n",
    "    Args:\n",
    "        p (float): probability of the image being permuted. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([N RO E1 ... ]): Image to be flipped.\n",
    "        Returns:\n",
    "            res: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:            \n",
    "            return ( np.transpose(img[0], (0, 2, 1)).copy(), np.transpose(img[1], (0, 2, 1)).copy(), img[2] )\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)    \n",
    "    \n",
    "class RandomCrop2DT(object):\n",
    "    \"\"\"Randomly crop the numpy array, fir 2D+T.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "    def __init__(self, roi, p=0.5, ro_range=(-24, 24), e1_range=(-24, 24), t_range=(-6, 6)):\n",
    "        self.p = p\n",
    "        self.ro_range = ro_range\n",
    "        self.e1_range = e1_range\n",
    "        self.t_range = t_range\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([Ro E1 N ... ]): Image to be cropped.\n",
    "        Returns:\n",
    "            res: Randomly cropped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "                \n",
    "            RO, E1, N = img[0].shape\n",
    "            \n",
    "            roi = img[2]\n",
    "            \n",
    "            ps_x = roi[0].astype(int)\n",
    "            pe_x = roi[1].astype(int)\n",
    "            ps_y = roi[2].astype(int)\n",
    "            pe_y = roi[3].astype(int)\n",
    "            aif_s = roi[4].astype(int)\n",
    "            aif_e  = roi[5].astype(int)\n",
    "                    \n",
    "            ro_shifts = np.random.randint(self.ro_range[0], self.ro_range[1]+1, 1)\n",
    "            e1_shifts = np.random.randint(self.e1_range[0], self.e1_range[1]+1, 1)\n",
    "            t_shifts = np.random.randint(self.t_range[0], self.t_range[1]+1, 1)\n",
    "                    \n",
    "            ss_ps_x = ps_x + ro_shifts\n",
    "            ss_ps_y = ps_y + e1_shifts\n",
    "            ss_ps_t = aif_s + t_shifts\n",
    "\n",
    "            ss_pe_x = pe_x + ro_shifts\n",
    "            ss_pe_y = pe_y + e1_shifts\n",
    "            ss_pe_t = aif_e + t_shifts\n",
    "\n",
    "            if(ss_ps_x<0 or ss_ps_y<0 or ss_ps_t<0):\n",
    "                return img\n",
    "\n",
    "            if(ss_pe_x>=RO and ss_pe_y>=E1 and ss_pe_t>=N):\n",
    "                return img\n",
    "                                                \n",
    "            a = img[0][ss_ps_t:ss_pe_t, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y]\n",
    "            b = np.expand_dims(img[1][0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)                                \n",
    "            \n",
    "            return ( a, b, img[2] )\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and apply random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "class PerfDatasetRandomCrop(Dataset):\n",
    "    \"\"\"Perfusion dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, which_mask='myo', num_of_random=9, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.which_mask = which_mask # myo or endo or epi\n",
    "        self.num_of_random = num_of_random\n",
    "        \n",
    "        self.ro_range = (-24, 24)\n",
    "        self.e1_range = (-24, 24)\n",
    "        self.t_range = (-6, 6)\n",
    "        \n",
    "        # find all images\n",
    "        a = []\n",
    "        for case_dir in self.img_dir:\n",
    "            locations = os.listdir(case_dir)            \n",
    "            for loc in locations:\n",
    "                if(os.path.isdir(os.path.join(case_dir, loc))):\n",
    "                    a.extend(os.listdir(os.path.join(case_dir, loc)))\n",
    "\n",
    "        num_samples = len(a)\n",
    "        print(\"Found %d cases ... \" % num_samples)\n",
    "        \n",
    "        self.Gd = []\n",
    "        self.endo_masks = []\n",
    "        self.epi_masks = []\n",
    "        self.myo_masks = []\n",
    "        self.endo_epi_masks = []\n",
    "        self.endo_epi_rvi_masks = []\n",
    "        self.endo_epi_rv_masks = []\n",
    "        self.endo_epi_rv_rvi_masks = []\n",
    "        self.rvi_pt = []\n",
    "        self.names = []\n",
    "\n",
    "        t0 = time.time()\n",
    "        print(\"Start loading cases ... \")\n",
    "        \n",
    "        total_case_loaded = 0\n",
    "        total_num_loaded = 0\n",
    "        \n",
    "        for case_dir in self.img_dir:\n",
    "            locations = os.listdir(case_dir) \n",
    "            for loc in locations:\n",
    "                a = os.listdir(os.path.join(case_dir, loc))\n",
    "                print('---> Start loading ', case_dir, loc)\n",
    "                for ii, n in enumerate(a):      \n",
    "\n",
    "\n",
    "                    #if (ii>5):\n",
    "                    #    break\n",
    "\n",
    "                    print('------> Start loading %d out of %d, %s' % (total_case_loaded, num_samples, n))\n",
    "                    name = os.path.join(loc, n)       \n",
    "\n",
    "                    is_seg_norm = True\n",
    "\n",
    "                    try:\n",
    "                        mat = scipy.io.loadmat(os.path.join(case_dir, name, 'Seg_norm.mat'))\n",
    "                    except:\n",
    "                        mat = scipy.io.loadmat(os.path.join(case_dir, name, 'Seg.mat'))\n",
    "                        is_seg_norm = False\n",
    "\n",
    "                    Seg = mat['Seg'] \n",
    "                    num_seg = len(Seg[0])\n",
    "\n",
    "                    Gd_all = self.load_one_data(case_dir, name, 'Gd_resized_norm')\n",
    "                    roi_all = self.load_one_data(case_dir, name, 'roi')\n",
    "\n",
    "                    total_case_loaded += 1\n",
    "\n",
    "                    for i in np.arange(num_seg):\n",
    "\n",
    "                        Gd = Gd_all[:,:,:,i]\n",
    "\n",
    "                        endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt, roi = self.load_from_Seg(Seg, i, is_seg_norm)\n",
    "                        Gd, endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt = self.load_from_numpy_array(Gd, endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt)\n",
    "\n",
    "                        # roi = roi_all.flatten()\n",
    "\n",
    "                        roi = roi.flatten()\n",
    "\n",
    "                        N, RO, E1 = Gd.shape\n",
    "\n",
    "                        ro_shifts = np.random.randint(self.ro_range[0], self.ro_range[1]+1, self.num_of_random)\n",
    "                        e1_shifts = np.random.randint(self.e1_range[0], self.e1_range[1]+1, self.num_of_random)\n",
    "                        t_shifts = np.random.randint(self.t_range[0], self.t_range[1]+1, self.num_of_random)\n",
    "\n",
    "                        ps_x = roi[0].astype(int)\n",
    "                        pe_x = roi[1].astype(int)\n",
    "                        ps_y = roi[2].astype(int)\n",
    "                        pe_y = roi[3].astype(int)\n",
    "                        aif_s = roi[4].astype(int)\n",
    "                        aif_e  = roi[5].astype(int)\n",
    "\n",
    "                        if (i==0):\n",
    "                            print('    ro, [start, end] = %d, %d; e1, [start, end] = %d, %d; t, [start, end] = %d, %d' % (ps_x, pe_x, ps_y, pe_y, aif_s, aif_e))\n",
    "\n",
    "                        # print('    Gd = %f, endo = %f, epi = %f' % (np.linalg.norm(Gd), np.linalg.norm(endo), np.linalg.norm(epi)))\n",
    "\n",
    "                        # random crop\n",
    "                        for rc in np.arange(self.num_of_random+1):\n",
    "\n",
    "                            if(rc==self.num_of_random):\n",
    "                                ss_ps_x = ps_x;\n",
    "                                ss_ps_y = ps_y;\n",
    "                                ss_ps_t = aif_s;\n",
    "\n",
    "                                ss_pe_x = pe_x;\n",
    "                                ss_pe_y = pe_y;\n",
    "                                ss_pe_t = aif_e;\n",
    "                            else:\n",
    "                                ss_ps_x = ps_x + ro_shifts[rc];\n",
    "                                ss_ps_y = ps_y + e1_shifts[rc];\n",
    "                                ss_ps_t = aif_s + t_shifts[rc];\n",
    "\n",
    "                                ss_pe_x = pe_x + ro_shifts[rc];\n",
    "                                ss_pe_y = pe_y + e1_shifts[rc];\n",
    "                                ss_pe_t = aif_e + t_shifts[rc];\n",
    "\n",
    "                            if(ss_ps_t<0):\n",
    "                                ss_ps_t=0\n",
    "                                ss_pe_t=48\n",
    "\n",
    "                            if(ss_pe_t>N):                            \n",
    "                                ss_pe_t=N\n",
    "                                ss_ps_t=ss_pe_t-48\n",
    "\n",
    "                            if(ss_ps_x<0 or ss_ps_y<0 or ss_ps_t<0):\n",
    "                                continue;\n",
    "\n",
    "                            if(ss_pe_x>RO and ss_pe_y>E1 and ss_pe_t>N):\n",
    "                                continue;\n",
    "\n",
    "\n",
    "                            Gd_s = Gd[ss_ps_t:ss_pe_t, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y]\n",
    "                            endo_s = np.expand_dims(endo[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            epi_s = np.expand_dims(epi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            myo_s = np.expand_dims(myo[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_s = np.expand_dims(endo_epi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_rv_s = np.expand_dims(endo_epi_rv[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_rvi_s = np.expand_dims(endo_epi_rvi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_rv_rvi_s = np.expand_dims(endo_epi_rv_rvi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "\n",
    "                            Gd_s = Gd_s / np.max(Gd_s)\n",
    "\n",
    "                            if(Gd_s.shape[0] != 48):\n",
    "                                continue;\n",
    "                            if(Gd_s.shape[1] != 176):\n",
    "                                continue;\n",
    "                            if(Gd_s.shape[2] != 176):\n",
    "                                continue;\n",
    "\n",
    "                            self.Gd.append(Gd_s)\n",
    "                            self.endo_masks.append(endo_s)\n",
    "                            self.epi_masks.append(epi_s)\n",
    "                            self.myo_masks.append(myo_s)\n",
    "                            self.endo_epi_masks.append(endo_epi_s)\n",
    "                            self.endo_epi_rv_masks.append(endo_epi_rv_s)\n",
    "                            self.endo_epi_rv_rvi_masks.append(endo_epi_rv_rvi_s)\n",
    "                            self.endo_epi_rvi_masks.append(endo_epi_rvi_s)\n",
    "                            self.rvi_pt.append(rvi_pt)\n",
    "\n",
    "                            self.names.append(name + '_' + str(i))\n",
    "\n",
    "                    total_num_loaded += (self.num_of_random+1)\n",
    "\n",
    "                    t1 = time.time()\n",
    "                    print(\"             Time from starting : %f seconds ... \\n\" % (t1-t0))\n",
    "\n",
    "                    #if total_num_loaded%100 == 0 and ii>0:\n",
    "                    #    print(\"load %d \" % total_num_loaded)                                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Gd)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if idx >= len(self.Gd):\n",
    "            raise \"invalid index\"\n",
    "        \n",
    "        if (self.which_mask == 'myo'):            \n",
    "            sample = (self.Gd[idx], self.myo_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo'):            \n",
    "            sample = (self.Gd[idx], self.endo_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'epi'):            \n",
    "            sample = (self.Gd[idx], self.epi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rvi'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_rvi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rv'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_rv_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rv_rvi'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_rv_rvi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rv,rvi'):            \n",
    "            sample = (self.Gd[idx], (self.endo_epi_rv_masks[idx], self.rvi_pt[idx]), self.names[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def load_one_data(self, case_dir, loc, f_prefix):\n",
    "        \n",
    "        f_name = f_prefix + '.npy'\n",
    "        data = np.load(os.path.join(case_dir, loc, f_name))                    \n",
    "                       \n",
    "        print ('Loaded ', f_name, data.shape)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_from_numpy_array(self, Gd, endo_mask, epi_mask, \\\n",
    "                              myo_mask, endo_epi_mask, endo_epi_rv_mask, \\\n",
    "                              endo_epi_rv_rv_insertion_mask, endo_epi_rv_insertion_mask, \\\n",
    "                              rv_insertion_pt):\n",
    "                       \n",
    "        \n",
    "        Gd = np.squeeze(Gd)\n",
    "        # Gd = Gd / np.max(Gd)\n",
    "        Gd = np.transpose(Gd, (2, 0, 1))\n",
    "                       \n",
    "        endo = endo_mask\n",
    "        endo = np.reshape(endo, (1, endo.shape[0], endo.shape[1]))\n",
    "                       \n",
    "        epi = epi_mask\n",
    "        epi = np.reshape(epi, (1, epi.shape[0], epi.shape[1]))\n",
    "        \n",
    "        myo = myo_mask\n",
    "        myo = np.reshape(myo, (1, myo.shape[0], myo.shape[1]))\n",
    "                       \n",
    "        endo_epi = endo_epi_mask\n",
    "        endo_epi = np.reshape(endo_epi, (1, endo_epi.shape[0], endo_epi.shape[1]))\n",
    "                       \n",
    "        endo_epi_rv = endo_epi_rv_mask\n",
    "        endo_epi_rv = np.reshape(endo_epi_rv, (1, endo_epi_rv.shape[0], endo_epi_rv.shape[1]))\n",
    "                       \n",
    "        endo_epi_rv_rvi = endo_epi_rv_rv_insertion_mask\n",
    "        endo_epi_rv_rvi = np.reshape(endo_epi_rv_rvi, (1, endo_epi_rv_rvi.shape[0], endo_epi_rv_rvi.shape[1]))\n",
    "                       \n",
    "        endo_epi_rvi = endo_epi_rv_insertion_mask\n",
    "        endo_epi_rvi = np.reshape(endo_epi_rvi, (1, endo_epi_rvi.shape[0], endo_epi_rvi.shape[1]))\n",
    "                       \n",
    "        rvi_pt = rv_insertion_pt\n",
    "                       \n",
    "        return Gd, endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt\n",
    "    \n",
    "    def load_from_Seg(self, Seg, ind, is_seg_norm):\n",
    "\n",
    "        if(is_seg_norm):\n",
    "            endo = Seg[0][ind]['endo_resized_mask_norm']\n",
    "            epi = Seg[0][ind]['epi_resized_mask_norm']\n",
    "            myo = Seg[0][ind]['myo_resized_mask_norm']\n",
    "            endo_epi = Seg[0][ind]['endo_epi_resized_mask_norm']\n",
    "            endo_epi_rv = Seg[0][ind]['endo_epi_rv_resized_mask_norm']\n",
    "            endo_epi_rv_rvi = Seg[0][ind]['endo_epi_rv_rvi_resized_mask_norm']\n",
    "            endo_epi_rvi = Seg[0][ind]['endo_epi_rvi_resized_mask_norm']\n",
    "            rvi_pt = Seg[0][ind]['rvi_resized_norm']\n",
    "            roi = Seg[0][ind]['roi_norm']\n",
    "        else:\n",
    "            endo = Seg[0][ind]['endo_resized_mask']\n",
    "            epi = Seg[0][ind]['epi_resized_mask']\n",
    "            myo = Seg[0][ind]['myo_resized_mask']\n",
    "            endo_epi = Seg[0][ind]['endo_epi_resized_mask']\n",
    "            endo_epi_rv = Seg[0][ind]['endo_epi_rv_resized_mask']\n",
    "            endo_epi_rv_rvi = Seg[0][ind]['endo_epi_rv_rvi_resized_mask']\n",
    "            endo_epi_rvi = Seg[0][ind]['endo_epi_rvi_resized_mask']\n",
    "            rvi_pt = Seg[0][ind]['rvi_resized']\n",
    "            roi = Seg[0][ind]['roi']\n",
    "            \n",
    "        '''print(Gd.shape)\n",
    "        print(endo.shape)\n",
    "        print(epi.shape)\n",
    "        print(myo.shape)\n",
    "        '''\n",
    "        \n",
    "        # Gd = Gd / np.max(Gd)\n",
    "\n",
    "        # Gd = np.transpose(Gd, (2, 0, 1))\n",
    "        '''\n",
    "        endo = np.reshape(endo, (1, endo.shape[0], endo.shape[1]))\n",
    "        epi = np.reshape(epi, (1, epi.shape[0], epi.shape[1]))\n",
    "        myo = np.reshape(myo, (1, myo.shape[0], myo.shape[1]))\n",
    "        endo_epi = np.reshape(endo_epi, (1, endo_epi.shape[0], endo_epi.shape[1]))\n",
    "        endo_epi_rv = np.reshape(endo_epi_rv, (1, endo_epi_rv.shape[0], endo_epi_rv.shape[1]))\n",
    "        endo_epi_rv_rvi = np.reshape(endo_epi_rv_rvi, (1, endo_epi_rv_rvi.shape[0], endo_epi_rv_rvi.shape[1]))\n",
    "        endo_epi_rvi = np.reshape(endo_epi_rvi, (1, endo_epi_rvi.shape[0], endo_epi_rvi.shape[1]))\n",
    "        '''\n",
    "        \n",
    "        return (endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt, roi)\n",
    "    \n",
    "    def __str__(self):\n",
    "        str = \"Perfusion Dataset\\n\"\n",
    "        str += \"  image root: %s\" % self.img_dir + \"\\n\"\n",
    "        str += \"  Number of samples: %d\" % len(self.Gd) + \"\\n\"\n",
    "        str += \"  Number of masks: %d\" % len(self.myo_masks) + \"\\n\"\n",
    "        if len(self.Gd) > 0:\n",
    "            str += \"  image shape: %d %d %d\" % self.Gd[0].shape + \"\\n\"\n",
    "            str += \"  myo mask shape: %d %d %d\" % self.myo_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo mask shape: %d %d %d\" % self.endo_masks[0].shape + \"\\n\"\n",
    "            str += \"  epi mask shape: %d %d %d\" % self.epi_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi mask shape: %d %d %d\" % self.endo_epi_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi_rv mask shape: %d %d %d\" % self.endo_epi_rv_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi_rvi mask shape: %d %d %d\" % self.endo_epi_rvi_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi_rv_rvi mask shape: %d %d %d\" % self.endo_epi_rv_rvi_masks[0].shape + \"\\n\"\n",
    "            str += \"  rvi_pt shape: %d %d\" % self.rvi_pt[0].shape + \"\\n\"\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_of_random = 16\n",
    "\n",
    "perf_dataset = PerfDatasetRandomCrop(img_dir, num_of_random=num_of_random)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([RandomFlip1stDim(0.5), RandomFlip2ndDim(0.5), RandomPermute2DT(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perf_dataset.which_mask = 'myo'\n",
    "sample = perf_dataset[1]\n",
    "\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)\n",
    "print(sample[2])\n",
    "\n",
    "im = np.transpose(sample[0], [1, 2, 0])\n",
    "utils.cmr_ml_utils_plotting.plot_image_array(im[:,:, 24], columns=1, figsize=[4, 4])\n",
    "\n",
    "a = torch.from_numpy(sample[0])\n",
    "b = torch.from_numpy(sample[1])\n",
    "\n",
    "perf_dataset.which_mask = 'endo'\n",
    "sample2 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'epi'\n",
    "sample3 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi'\n",
    "sample4 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi_rv'\n",
    "sample5 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi_rv_rvi'\n",
    "sample6 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi_rvi'\n",
    "sample7 = perf_dataset[1]\n",
    "\n",
    "plt.figure(figsize=(32, 32))\n",
    "plt.subplot(171)\n",
    "plt.imshow(np.squeeze(sample[1]))\n",
    "plt.subplot(172)\n",
    "plt.imshow(np.squeeze(sample2[1]))\n",
    "plt.subplot(173)\n",
    "plt.imshow(np.squeeze(sample3[1]))\n",
    "plt.subplot(174)\n",
    "plt.imshow(np.squeeze(sample4[1]))\n",
    "plt.subplot(175)\n",
    "plt.imshow(np.squeeze(sample5[1]))\n",
    "plt.subplot(176)\n",
    "plt.imshow(np.squeeze(sample6[1]))\n",
    "plt.subplot(177)\n",
    "plt.imshow(np.squeeze(sample7[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with multi-calss segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([RandomFlip1stDim(0.5), RandomFlip2ndDim(0.5), RandomPermute2DT(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_random = 16\n",
    "\n",
    "perf_dataset = PerfDatasetRandomCrop(img_dir, num_of_random=num_of_random)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.cmr_ml_utils_data\n",
    "\n",
    "k = 12\n",
    "\n",
    "# Chunk into k random sets\n",
    "chunks = utils.cmr_ml_utils_data.chunk(range(len(perf_dataset)), k)\n",
    "train_idxs, val_idxs = utils.cmr_ml_utils_data.get_k_fold_training_validation(chunks, val_chunk=0)\n",
    "\n",
    "num_train = len(train_idxs)\n",
    "print('num_train = %d' % num_train)\n",
    "num_val = len(val_idxs)\n",
    "print('num_val = %d' % num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.which_mask = 'endo_epi_rv'\n",
    "num_classes = 4\n",
    "class_for_accu = [1, 2, 3] # endo,epi, rv\n",
    "class_weights = np.ones(num_classes)\n",
    "print(class_weights)\n",
    "p_thres = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset.which_mask)\n",
    "\n",
    "sample = perf_dataset[1]\n",
    "\n",
    "print(sample[1].shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "loader_for_train = DataLoader(perf_dataset, batch_size=batch_size, \n",
    "                          sampler=sampler.SubsetRandomSampler(train_idxs))\n",
    "\n",
    "loader_for_val = DataLoader(perf_dataset, batch_size=batch_size, \n",
    "                        sampler=sampler.SubsetRandomSampler(val_idxs))\n",
    "\n",
    "iter_train = iter(loader_for_train)\n",
    "\n",
    "print(perf_dataset.which_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks, names = iter_train.next()\n",
    "\n",
    "B, C, RO, E1 = images.shape\n",
    "\n",
    "print(images.shape)\n",
    "print(masks.shape)\n",
    "print(torch.max(images))\n",
    "print(torch.max(masks))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(masks[1,0,:,:]))\n",
    "\n",
    "a = images[:,0,:,:]\n",
    "print(a.shape)\n",
    "a = torch.reshape(a, (B, 1, RO, E1))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "show(make_grid(a.double(), nrow=8, padding=2, normalize=False, scale_each=True))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "show(make_grid(masks.double(), nrow=8, padding=2, normalize=True, scale_each=False))\n",
    "\n",
    "print(images.dtype)\n",
    "X = images.type(torch.FloatTensor)\n",
    "y = masks.type(torch.FloatTensor)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training\n",
    "import models\n",
    "import hyper_search\n",
    "import plot_run\n",
    "from training import dice_coeff, centroid_diff, adaptive_thresh\n",
    "\n",
    "num_epochs = 120\n",
    "print_every = 100000\n",
    "\n",
    "inplanes = 96\n",
    "layers=[2, 3]\n",
    "layers_planes=[96, 128]\n",
    "\n",
    "print(perf_dataset.Gd[0].shape)\n",
    "C, H, W = perf_dataset.Gd[0].shape\n",
    "\n",
    "model = models.GadgetronResUnet18(F0=C, \n",
    "                                  inplanes=inplanes, \n",
    "                                  layers=layers, \n",
    "                                  layers_planes=layers_planes, \n",
    "                                  use_dropout=False, \n",
    "                                  p=0.5, \n",
    "                                  H=H, W=W, C=num_classes, # background, lv, myo, rv, rv insertion\n",
    "                                  verbose=True)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(\"model on multiple GPU ... \")\n",
    "    # print(model)\n",
    "\n",
    "patience = 5\n",
    "factor = 0.5\n",
    "cooldown = 1\n",
    "min_lr = 1e-5\n",
    "\n",
    "weight_decay=0\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=20, verbose=True)\n",
    "\n",
    "criterion = training.LossMulti(class_weights=class_weights, jaccard_weight=0.5)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "log_dir = 'perf_training/ResUnet' + '_lr_' + str(learning_rate) + '_epochs_' + str(num_epochs)\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_trainer = training.GadgetronMultiClassSeg_Perf(model, \n",
    "                                   optimizer, \n",
    "                                   criterion, \n",
    "                                   loader_for_train, \n",
    "                                   loader_for_val, \n",
    "                                   class_for_accu=class_for_accu,\n",
    "                                   p_thres = p_thres,\n",
    "                                   scheduler=scheduler, \n",
    "                                   epochs=num_epochs, \n",
    "                                   device=device, \n",
    "                                   x_dtype=torch.float32, \n",
    "                                   y_dtype=torch.long, \n",
    "                                   early_stopping_thres = 100,                              \n",
    "                                   print_every=print_every,\n",
    "                                   small_data_mode = False, \n",
    "                                   writer=writer, \n",
    "                                   model_folder=\"perf_training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs_traning, epochs_validation, best_model, loss_all, epochs_acc_class = perf_trainer.train(verbose=True, epoch_to_load=-1, save_model_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss, acc_class = perf_trainer.check_validation_test_accuracy(loader_for_val, best_model)\n",
    "print(acc, loss)\n",
    "print(acc_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    best_model_cpu = best_model.cpu().module\n",
    "except:\n",
    "    \n",
    "    best_model_cpu = best_model.cpu()\n",
    "    \n",
    "print(best_model_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset.transform)\n",
    "v = torch.__version__\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(perf_dataset.transform==None):\n",
    "    model_file = '/home/xueh2/mrprogs/gadgetron_CMR_ML-source/deployment/networks/perf_' + perf_dataset.which_mask + '_network_' + today + '_CMR_View' + '_Pytorch_' + v + '.pbt'\n",
    "else:\n",
    "    model_file = '/home/xueh2/mrprogs/gadgetron_CMR_ML-source/deployment/networks/perf_' + perf_dataset.which_mask + '_network_' + today + '_Pytorch_' + v  + '.pbt'\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Correct save!\n",
    "import copy \n",
    "\n",
    "best_model_wts = copy.deepcopy(best_model_cpu.cpu().state_dict())\n",
    "\n",
    "empty_model = models.GadgetronResUnet18(F0=C, \n",
    "                                  inplanes=inplanes, \n",
    "                                  layers=layers, \n",
    "                                  layers_planes=layers_planes, \n",
    "                                  use_dropout=False, \n",
    "                                  p=0.5, \n",
    "                                  H=H, W=W, C=num_classes, \n",
    "                                  verbose=True)\n",
    "empty_model.load_state_dict(best_model_wts)\n",
    "\n",
    "#print(empty_model)\n",
    "\n",
    "#torch.save(empty_model.state_dict(), '/home/xueh2/cmr_ml/deployment/networks/abstract_network.dict')\n",
    "torch.save(empty_model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test\n",
    "# work with python application\n",
    "# Runs on CPU so very slow\n",
    "\n",
    "model_loaded = torch.load(model_file)\n",
    "\n",
    "print(model_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
