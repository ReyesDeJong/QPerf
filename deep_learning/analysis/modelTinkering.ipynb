{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfusion mapping analysis using deep learning\n",
    "**Author**: `Hui Xue <hui.xue@nih.gov>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:90% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='1,2'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.onnx\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import *\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "animation.rcParams['animation.writer'] = 'ffmpeg'\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "import scipy\n",
    "import scipy as sp\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# from skimage import io, transform\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from IPython.display import display, clear_output, HTML, Image\n",
    "\n",
    "from PIL import Image\n",
    "import imp\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "#print(os.getcwd())\n",
    "#os.mkdir('./DebugOutput')\n",
    "\n",
    "def save_as_image(a, img_name='test', img_dir='./DebugOutput'):\n",
    "    N, C, H, W = a.shape\n",
    "    \n",
    "    a = np.transpose(a, (2, 3, 1, 0))\n",
    "    \n",
    "    for n in range(N):\n",
    "        filename = os.path.join(img_dir, img_name + str(n) + '.tif')\n",
    "        if C==3:\n",
    "            plt.imsave(filename, a[:,:,:,n])\n",
    "            continue\n",
    "        if C==1:\n",
    "            plt.imsave(filename, a[:,:,0,n])\n",
    "            continue\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (performance.py, line 17)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "  File \u001B[1;32m\"/home/esteban/anaconda3/envs/torch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001B[0m, line \u001B[1;32m3343\u001B[0m, in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001B[1;32m\"<ipython-input-2-8e86ed36a8c3>\"\u001B[0m, line \u001B[1;32m3\u001B[0m, in \u001B[1;35m<module>\u001B[0m\n    from deep_learning.analysis import training\n",
      "\u001B[0;36m  File \u001B[0;32m\"/home/esteban/Projects/Miocardium/QPerf/deep_learning/analysis/training/__init__.py\"\u001B[0;36m, line \u001B[0;32m1\u001B[0;36m, in \u001B[0;35m<module>\u001B[0;36m\u001B[0m\n\u001B[0;31m    from .performance import *\u001B[0m\n",
      "\u001B[0;36m  File \u001B[0;32m\"/home/esteban/Projects/Miocardium/QPerf/deep_learning/analysis/training/performance.py\"\u001B[0;36m, line \u001B[0;32m17\u001B[0m\n\u001B[0;31m    return x.cuda(async=True) if torch.cuda.is_available() else x\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from deep_learning.analysis import training\n",
    "from deep_learning.analysis import models\n",
    "# import hyper_search\n",
    "# import plot_run\n",
    "from deep_learning.analysis  import utils\n",
    "from deep_learning.analysis.utils import cmr_ml_utils_data\n",
    "from deep_learning.analysis.utils import cmr_ml_utils_plotting\n",
    "\n",
    "# dir(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = ['/mnt/disk1/TrainingData/Perf_SAX_SEG', '/mnt/disk1/TrainingData/Perf_SAX_SEG_Set2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFlip1stDim(object):\n",
    "    \"\"\"Randomly flip the first dimension of numpy array.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([N RO E1 ... ]): Image to be flipped.\n",
    "        Returns:\n",
    "            res: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        #print(img[0].shape)\n",
    "        #print(img[1].shape)\n",
    "            \n",
    "        if random.random() < self.p: \n",
    "                                \n",
    "            a = np.transpose(img[0], [1, 2, 0])\n",
    "            a = np.flipud(a)\n",
    "            a = np.transpose(a, [2, 0, 1])\n",
    "            \n",
    "            b = np.transpose(img[1], [1, 2, 0])\n",
    "            b = np.flipud(b)\n",
    "            b = np.transpose(b, [2, 0, 1])\n",
    "            return ( a.copy(), b.copy(), img[2] )\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "    \n",
    "class RandomFlip2ndDim(object):\n",
    "    \"\"\"Randomly flip the second dimension of numpy array.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([N RO E1 ... ]): Image to be flipped.\n",
    "        Returns:\n",
    "            res: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:    \n",
    "            a = np.transpose(img[0], [1, 2, 0])\n",
    "            a = np.fliplr(a)\n",
    "            a = np.transpose(a, [2, 0, 1])\n",
    "            \n",
    "            b = np.transpose(img[1], [1, 2, 0])\n",
    "            b = np.fliplr(b)\n",
    "            b = np.transpose(b, [2, 0, 1])\n",
    "            return ( a.copy(), b.copy(), img[2] )\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "    \n",
    "class RandomPermute2DT(object):\n",
    "    \"\"\"Randomly permute 1st and 2nd dimensions of numpy array.\n",
    "    Args:\n",
    "        p (float): probability of the image being permuted. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([N RO E1 ... ]): Image to be flipped.\n",
    "        Returns:\n",
    "            res: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:            \n",
    "            return ( np.transpose(img[0], (0, 2, 1)).copy(), np.transpose(img[1], (0, 2, 1)).copy(), img[2] )\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)    \n",
    "    \n",
    "class RandomCrop2DT(object):\n",
    "    \"\"\"Randomly crop the numpy array, fir 2D+T.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "    def __init__(self, roi, p=0.5, ro_range=(-24, 24), e1_range=(-24, 24), t_range=(-6, 6)):\n",
    "        self.p = p\n",
    "        self.ro_range = ro_range\n",
    "        self.e1_range = e1_range\n",
    "        self.t_range = t_range\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img ([Ro E1 N ... ]): Image to be cropped.\n",
    "        Returns:\n",
    "            res: Randomly cropped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "                \n",
    "            RO, E1, N = img[0].shape\n",
    "            \n",
    "            roi = img[2]\n",
    "            \n",
    "            ps_x = roi[0].astype(int)\n",
    "            pe_x = roi[1].astype(int)\n",
    "            ps_y = roi[2].astype(int)\n",
    "            pe_y = roi[3].astype(int)\n",
    "            aif_s = roi[4].astype(int)\n",
    "            aif_e  = roi[5].astype(int)\n",
    "                    \n",
    "            ro_shifts = np.random.randint(self.ro_range[0], self.ro_range[1]+1, 1)\n",
    "            e1_shifts = np.random.randint(self.e1_range[0], self.e1_range[1]+1, 1)\n",
    "            t_shifts = np.random.randint(self.t_range[0], self.t_range[1]+1, 1)\n",
    "                    \n",
    "            ss_ps_x = ps_x + ro_shifts\n",
    "            ss_ps_y = ps_y + e1_shifts\n",
    "            ss_ps_t = aif_s + t_shifts\n",
    "\n",
    "            ss_pe_x = pe_x + ro_shifts\n",
    "            ss_pe_y = pe_y + e1_shifts\n",
    "            ss_pe_t = aif_e + t_shifts\n",
    "\n",
    "            if(ss_ps_x<0 or ss_ps_y<0 or ss_ps_t<0):\n",
    "                return img\n",
    "\n",
    "            if(ss_pe_x>=RO and ss_pe_y>=E1 and ss_pe_t>=N):\n",
    "                return img\n",
    "                                                \n",
    "            a = img[0][ss_ps_t:ss_pe_t, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y]\n",
    "            b = np.expand_dims(img[1][0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)                                \n",
    "            \n",
    "            return ( a, b, img[2] )\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and apply random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "class PerfDatasetRandomCrop(Dataset):\n",
    "    \"\"\"Perfusion dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, which_mask='myo', num_of_random=9, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.which_mask = which_mask # myo or endo or epi\n",
    "        self.num_of_random = num_of_random\n",
    "        \n",
    "        self.ro_range = (-24, 24)\n",
    "        self.e1_range = (-24, 24)\n",
    "        self.t_range = (-6, 6)\n",
    "        \n",
    "        # find all images\n",
    "        a = []\n",
    "        for case_dir in self.img_dir:\n",
    "            locations = os.listdir(case_dir)            \n",
    "            for loc in locations:\n",
    "                if(os.path.isdir(os.path.join(case_dir, loc))):\n",
    "                    a.extend(os.listdir(os.path.join(case_dir, loc)))\n",
    "\n",
    "        num_samples = len(a)\n",
    "        print(\"Found %d cases ... \" % num_samples)\n",
    "        \n",
    "        self.Gd = []\n",
    "        self.endo_masks = []\n",
    "        self.epi_masks = []\n",
    "        self.myo_masks = []\n",
    "        self.endo_epi_masks = []\n",
    "        self.endo_epi_rvi_masks = []\n",
    "        self.endo_epi_rv_masks = []\n",
    "        self.endo_epi_rv_rvi_masks = []\n",
    "        self.rvi_pt = []\n",
    "        self.names = []\n",
    "\n",
    "        t0 = time.time()\n",
    "        print(\"Start loading cases ... \")\n",
    "        \n",
    "        total_case_loaded = 0\n",
    "        total_num_loaded = 0\n",
    "        \n",
    "        for case_dir in self.img_dir:\n",
    "            locations = os.listdir(case_dir) \n",
    "            for loc in locations:\n",
    "                a = os.listdir(os.path.join(case_dir, loc))\n",
    "                print('---> Start loading ', case_dir, loc)\n",
    "                for ii, n in enumerate(a):      \n",
    "\n",
    "\n",
    "                    #if (ii>5):\n",
    "                    #    break\n",
    "\n",
    "                    print('------> Start loading %d out of %d, %s' % (total_case_loaded, num_samples, n))\n",
    "                    name = os.path.join(loc, n)       \n",
    "\n",
    "                    is_seg_norm = True\n",
    "\n",
    "                    try:\n",
    "                        mat = scipy.io.loadmat(os.path.join(case_dir, name, 'Seg_norm.mat'))\n",
    "                    except:\n",
    "                        mat = scipy.io.loadmat(os.path.join(case_dir, name, 'Seg.mat'))\n",
    "                        is_seg_norm = False\n",
    "\n",
    "                    Seg = mat['Seg'] \n",
    "                    num_seg = len(Seg[0])\n",
    "\n",
    "                    Gd_all = self.load_one_data(case_dir, name, 'Gd_resized_norm')\n",
    "                    roi_all = self.load_one_data(case_dir, name, 'roi')\n",
    "\n",
    "                    total_case_loaded += 1\n",
    "\n",
    "                    for i in np.arange(num_seg):\n",
    "\n",
    "                        Gd = Gd_all[:,:,:,i]\n",
    "\n",
    "                        endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt, roi = self.load_from_Seg(Seg, i, is_seg_norm)\n",
    "                        Gd, endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt = self.load_from_numpy_array(Gd, endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt)\n",
    "\n",
    "                        # roi = roi_all.flatten()\n",
    "\n",
    "                        roi = roi.flatten()\n",
    "\n",
    "                        N, RO, E1 = Gd.shape\n",
    "\n",
    "                        ro_shifts = np.random.randint(self.ro_range[0], self.ro_range[1]+1, self.num_of_random)\n",
    "                        e1_shifts = np.random.randint(self.e1_range[0], self.e1_range[1]+1, self.num_of_random)\n",
    "                        t_shifts = np.random.randint(self.t_range[0], self.t_range[1]+1, self.num_of_random)\n",
    "\n",
    "                        ps_x = roi[0].astype(int)\n",
    "                        pe_x = roi[1].astype(int)\n",
    "                        ps_y = roi[2].astype(int)\n",
    "                        pe_y = roi[3].astype(int)\n",
    "                        aif_s = roi[4].astype(int)\n",
    "                        aif_e  = roi[5].astype(int)\n",
    "\n",
    "                        if (i==0):\n",
    "                            print('    ro, [start, end] = %d, %d; e1, [start, end] = %d, %d; t, [start, end] = %d, %d' % (ps_x, pe_x, ps_y, pe_y, aif_s, aif_e))\n",
    "\n",
    "                        # print('    Gd = %f, endo = %f, epi = %f' % (np.linalg.norm(Gd), np.linalg.norm(endo), np.linalg.norm(epi)))\n",
    "\n",
    "                        # random crop\n",
    "                        for rc in np.arange(self.num_of_random+1):\n",
    "\n",
    "                            if(rc==self.num_of_random):\n",
    "                                ss_ps_x = ps_x;\n",
    "                                ss_ps_y = ps_y;\n",
    "                                ss_ps_t = aif_s;\n",
    "\n",
    "                                ss_pe_x = pe_x;\n",
    "                                ss_pe_y = pe_y;\n",
    "                                ss_pe_t = aif_e;\n",
    "                            else:\n",
    "                                ss_ps_x = ps_x + ro_shifts[rc];\n",
    "                                ss_ps_y = ps_y + e1_shifts[rc];\n",
    "                                ss_ps_t = aif_s + t_shifts[rc];\n",
    "\n",
    "                                ss_pe_x = pe_x + ro_shifts[rc];\n",
    "                                ss_pe_y = pe_y + e1_shifts[rc];\n",
    "                                ss_pe_t = aif_e + t_shifts[rc];\n",
    "\n",
    "                            if(ss_ps_t<0):\n",
    "                                ss_ps_t=0\n",
    "                                ss_pe_t=48\n",
    "\n",
    "                            if(ss_pe_t>N):                            \n",
    "                                ss_pe_t=N\n",
    "                                ss_ps_t=ss_pe_t-48\n",
    "\n",
    "                            if(ss_ps_x<0 or ss_ps_y<0 or ss_ps_t<0):\n",
    "                                continue;\n",
    "\n",
    "                            if(ss_pe_x>RO and ss_pe_y>E1 and ss_pe_t>N):\n",
    "                                continue;\n",
    "\n",
    "\n",
    "                            Gd_s = Gd[ss_ps_t:ss_pe_t, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y]\n",
    "                            endo_s = np.expand_dims(endo[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            epi_s = np.expand_dims(epi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            myo_s = np.expand_dims(myo[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_s = np.expand_dims(endo_epi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_rv_s = np.expand_dims(endo_epi_rv[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_rvi_s = np.expand_dims(endo_epi_rvi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "                            endo_epi_rv_rvi_s = np.expand_dims(endo_epi_rv_rvi[0, ss_ps_x:ss_pe_x, ss_ps_y:ss_pe_y], axis=0)\n",
    "\n",
    "                            Gd_s = Gd_s / np.max(Gd_s)\n",
    "\n",
    "                            if(Gd_s.shape[0] != 48):\n",
    "                                continue;\n",
    "                            if(Gd_s.shape[1] != 176):\n",
    "                                continue;\n",
    "                            if(Gd_s.shape[2] != 176):\n",
    "                                continue;\n",
    "\n",
    "                            self.Gd.append(Gd_s)\n",
    "                            self.endo_masks.append(endo_s)\n",
    "                            self.epi_masks.append(epi_s)\n",
    "                            self.myo_masks.append(myo_s)\n",
    "                            self.endo_epi_masks.append(endo_epi_s)\n",
    "                            self.endo_epi_rv_masks.append(endo_epi_rv_s)\n",
    "                            self.endo_epi_rv_rvi_masks.append(endo_epi_rv_rvi_s)\n",
    "                            self.endo_epi_rvi_masks.append(endo_epi_rvi_s)\n",
    "                            self.rvi_pt.append(rvi_pt)\n",
    "\n",
    "                            self.names.append(name + '_' + str(i))\n",
    "\n",
    "                    total_num_loaded += (self.num_of_random+1)\n",
    "\n",
    "                    t1 = time.time()\n",
    "                    print(\"             Time from starting : %f seconds ... \\n\" % (t1-t0))\n",
    "\n",
    "                    #if total_num_loaded%100 == 0 and ii>0:\n",
    "                    #    print(\"load %d \" % total_num_loaded)                                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Gd)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if idx >= len(self.Gd):\n",
    "            raise Exception(\"invalid index\")\n",
    "        \n",
    "        if (self.which_mask == 'myo'):            \n",
    "            sample = (self.Gd[idx], self.myo_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo'):            \n",
    "            sample = (self.Gd[idx], self.endo_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'epi'):            \n",
    "            sample = (self.Gd[idx], self.epi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rvi'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_rvi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rv'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_rv_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rv_rvi'):            \n",
    "            sample = (self.Gd[idx], self.endo_epi_rv_rvi_masks[idx], self.names[idx])\n",
    "            \n",
    "        if (self.which_mask == 'endo_epi_rv,rvi'):            \n",
    "            sample = (self.Gd[idx], (self.endo_epi_rv_masks[idx], self.rvi_pt[idx]), self.names[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def load_one_data(self, case_dir, loc, f_prefix):\n",
    "        \n",
    "        f_name = f_prefix + '.npy'\n",
    "        data = np.load(os.path.join(case_dir, loc, f_name))                    \n",
    "                       \n",
    "        print ('Loaded ', f_name, data.shape)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_from_numpy_array(self, Gd, endo_mask, epi_mask, \\\n",
    "                              myo_mask, endo_epi_mask, endo_epi_rv_mask, \\\n",
    "                              endo_epi_rv_rv_insertion_mask, endo_epi_rv_insertion_mask, \\\n",
    "                              rv_insertion_pt):\n",
    "                       \n",
    "        \n",
    "        Gd = np.squeeze(Gd)\n",
    "        # Gd = Gd / np.max(Gd)\n",
    "        Gd = np.transpose(Gd, (2, 0, 1))\n",
    "                       \n",
    "        endo = endo_mask\n",
    "        endo = np.reshape(endo, (1, endo.shape[0], endo.shape[1]))\n",
    "                       \n",
    "        epi = epi_mask\n",
    "        epi = np.reshape(epi, (1, epi.shape[0], epi.shape[1]))\n",
    "        \n",
    "        myo = myo_mask\n",
    "        myo = np.reshape(myo, (1, myo.shape[0], myo.shape[1]))\n",
    "                       \n",
    "        endo_epi = endo_epi_mask\n",
    "        endo_epi = np.reshape(endo_epi, (1, endo_epi.shape[0], endo_epi.shape[1]))\n",
    "                       \n",
    "        endo_epi_rv = endo_epi_rv_mask\n",
    "        endo_epi_rv = np.reshape(endo_epi_rv, (1, endo_epi_rv.shape[0], endo_epi_rv.shape[1]))\n",
    "                       \n",
    "        endo_epi_rv_rvi = endo_epi_rv_rv_insertion_mask\n",
    "        endo_epi_rv_rvi = np.reshape(endo_epi_rv_rvi, (1, endo_epi_rv_rvi.shape[0], endo_epi_rv_rvi.shape[1]))\n",
    "                       \n",
    "        endo_epi_rvi = endo_epi_rv_insertion_mask\n",
    "        endo_epi_rvi = np.reshape(endo_epi_rvi, (1, endo_epi_rvi.shape[0], endo_epi_rvi.shape[1]))\n",
    "                       \n",
    "        rvi_pt = rv_insertion_pt\n",
    "                       \n",
    "        return Gd, endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt\n",
    "    \n",
    "    def load_from_Seg(self, Seg, ind, is_seg_norm):\n",
    "\n",
    "        if(is_seg_norm):\n",
    "            endo = Seg[0][ind]['endo_resized_mask_norm']\n",
    "            epi = Seg[0][ind]['epi_resized_mask_norm']\n",
    "            myo = Seg[0][ind]['myo_resized_mask_norm']\n",
    "            endo_epi = Seg[0][ind]['endo_epi_resized_mask_norm']\n",
    "            endo_epi_rv = Seg[0][ind]['endo_epi_rv_resized_mask_norm']\n",
    "            endo_epi_rv_rvi = Seg[0][ind]['endo_epi_rv_rvi_resized_mask_norm']\n",
    "            endo_epi_rvi = Seg[0][ind]['endo_epi_rvi_resized_mask_norm']\n",
    "            rvi_pt = Seg[0][ind]['rvi_resized_norm']\n",
    "            roi = Seg[0][ind]['roi_norm']\n",
    "        else:\n",
    "            endo = Seg[0][ind]['endo_resized_mask']\n",
    "            epi = Seg[0][ind]['epi_resized_mask']\n",
    "            myo = Seg[0][ind]['myo_resized_mask']\n",
    "            endo_epi = Seg[0][ind]['endo_epi_resized_mask']\n",
    "            endo_epi_rv = Seg[0][ind]['endo_epi_rv_resized_mask']\n",
    "            endo_epi_rv_rvi = Seg[0][ind]['endo_epi_rv_rvi_resized_mask']\n",
    "            endo_epi_rvi = Seg[0][ind]['endo_epi_rvi_resized_mask']\n",
    "            rvi_pt = Seg[0][ind]['rvi_resized']\n",
    "            roi = Seg[0][ind]['roi']\n",
    "            \n",
    "        '''print(Gd.shape)\n",
    "        print(endo.shape)\n",
    "        print(epi.shape)\n",
    "        print(myo.shape)\n",
    "        '''\n",
    "        \n",
    "        # Gd = Gd / np.max(Gd)\n",
    "\n",
    "        # Gd = np.transpose(Gd, (2, 0, 1))\n",
    "        '''\n",
    "        endo = np.reshape(endo, (1, endo.shape[0], endo.shape[1]))\n",
    "        epi = np.reshape(epi, (1, epi.shape[0], epi.shape[1]))\n",
    "        myo = np.reshape(myo, (1, myo.shape[0], myo.shape[1]))\n",
    "        endo_epi = np.reshape(endo_epi, (1, endo_epi.shape[0], endo_epi.shape[1]))\n",
    "        endo_epi_rv = np.reshape(endo_epi_rv, (1, endo_epi_rv.shape[0], endo_epi_rv.shape[1]))\n",
    "        endo_epi_rv_rvi = np.reshape(endo_epi_rv_rvi, (1, endo_epi_rv_rvi.shape[0], endo_epi_rv_rvi.shape[1]))\n",
    "        endo_epi_rvi = np.reshape(endo_epi_rvi, (1, endo_epi_rvi.shape[0], endo_epi_rvi.shape[1]))\n",
    "        '''\n",
    "        \n",
    "        return (endo, epi, myo, endo_epi, endo_epi_rv, endo_epi_rv_rvi, endo_epi_rvi, rvi_pt, roi)\n",
    "    \n",
    "    def __str__(self):\n",
    "        str = \"Perfusion Dataset\\n\"\n",
    "        str += \"  image root: %s\" % self.img_dir + \"\\n\"\n",
    "        str += \"  Number of samples: %d\" % len(self.Gd) + \"\\n\"\n",
    "        str += \"  Number of masks: %d\" % len(self.myo_masks) + \"\\n\"\n",
    "        if len(self.Gd) > 0:\n",
    "            str += \"  image shape: %d %d %d\" % self.Gd[0].shape + \"\\n\"\n",
    "            str += \"  myo mask shape: %d %d %d\" % self.myo_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo mask shape: %d %d %d\" % self.endo_masks[0].shape + \"\\n\"\n",
    "            str += \"  epi mask shape: %d %d %d\" % self.epi_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi mask shape: %d %d %d\" % self.endo_epi_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi_rv mask shape: %d %d %d\" % self.endo_epi_rv_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi_rvi mask shape: %d %d %d\" % self.endo_epi_rvi_masks[0].shape + \"\\n\"\n",
    "            str += \"  endo_epi_rv_rvi mask shape: %d %d %d\" % self.endo_epi_rv_rvi_masks[0].shape + \"\\n\"\n",
    "            str += \"  rvi_pt shape: %d %d\" % self.rvi_pt[0].shape + \"\\n\"\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_of_random = 16\n",
    "\n",
    "perf_dataset = PerfDatasetRandomCrop(img_dir, num_of_random=num_of_random)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([RandomFlip1stDim(0.5), RandomFlip2ndDim(0.5), RandomPermute2DT(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perf_dataset.which_mask = 'myo'\n",
    "sample = perf_dataset[1]\n",
    "\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)\n",
    "print(sample[2])\n",
    "\n",
    "im = np.transpose(sample[0], [1, 2, 0])\n",
    "utils.cmr_ml_utils_plotting.plot_image_array(im[:,:, 24], columns=1, figsize=[4, 4])\n",
    "\n",
    "a = torch.from_numpy(sample[0])\n",
    "b = torch.from_numpy(sample[1])\n",
    "\n",
    "perf_dataset.which_mask = 'endo'\n",
    "sample2 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'epi'\n",
    "sample3 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi'\n",
    "sample4 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi_rv'\n",
    "sample5 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi_rv_rvi'\n",
    "sample6 = perf_dataset[1]\n",
    "\n",
    "perf_dataset.which_mask = 'endo_epi_rvi'\n",
    "sample7 = perf_dataset[1]\n",
    "\n",
    "plt.figure(figsize=(32, 32))\n",
    "plt.subplot(171)\n",
    "plt.imshow(np.squeeze(sample[1]))\n",
    "plt.subplot(172)\n",
    "plt.imshow(np.squeeze(sample2[1]))\n",
    "plt.subplot(173)\n",
    "plt.imshow(np.squeeze(sample3[1]))\n",
    "plt.subplot(174)\n",
    "plt.imshow(np.squeeze(sample4[1]))\n",
    "plt.subplot(175)\n",
    "plt.imshow(np.squeeze(sample5[1]))\n",
    "plt.subplot(176)\n",
    "plt.imshow(np.squeeze(sample6[1]))\n",
    "plt.subplot(177)\n",
    "plt.imshow(np.squeeze(sample7[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with multi-calss segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([RandomFlip1stDim(0.5), RandomFlip2ndDim(0.5), RandomPermute2DT(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_random = 16\n",
    "\n",
    "perf_dataset = PerfDatasetRandomCrop(img_dir, num_of_random=num_of_random)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dataset.transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning.analysis.utils import cmr_ml_utils_data\n",
    "\n",
    "k = 12\n",
    "\n",
    "# Chunk into k random sets\n",
    "chunks = utils.cmr_ml_utils_data.chunk(range(len(perf_dataset)), k)\n",
    "train_idxs, val_idxs = utils.cmr_ml_utils_data.get_k_fold_training_validation(chunks, val_chunk=0)\n",
    "\n",
    "num_train = len(train_idxs)\n",
    "print('num_train = %d' % num_train)\n",
    "num_val = len(val_idxs)\n",
    "print('num_val = %d' % num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# perf_dataset.which_mask = 'endo_epi_rv'\n",
    "num_classes = 4\n",
    "class_for_accu = [1, 2, 3] # endo,epi, rv\n",
    "class_weights = np.ones(num_classes)\n",
    "print(class_weights)\n",
    "p_thres = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(perf_dataset.which_mask)\n",
    "#\n",
    "# sample = perf_dataset[1]\n",
    "#\n",
    "# print(sample[1].shape)\n",
    "#\n",
    "# plt.figure()\n",
    "# plt.imshow(np.squeeze(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# loader_for_train = DataLoader(perf_dataset, batch_size=batch_size,\n",
    "#                           sampler=sampler.SubsetRandomSampler(train_idxs))\n",
    "#\n",
    "# loader_for_val = DataLoader(perf_dataset, batch_size=batch_size,\n",
    "#                         sampler=sampler.SubsetRandomSampler(val_idxs))\n",
    "#\n",
    "# iter_train = iter(loader_for_train)\n",
    "#\n",
    "# print(perf_dataset.which_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, masks, names = iter_train.next()\n",
    "#\n",
    "# B, C, RO, E1 = images.shape\n",
    "#\n",
    "# print(images.shape)\n",
    "# print(masks.shape)\n",
    "# print(torch.max(images))\n",
    "# print(torch.max(masks))\n",
    "#\n",
    "# plt.figure()\n",
    "# plt.imshow(np.squeeze(masks[1,0,:,:]))\n",
    "#\n",
    "# a = images[:,0,:,:]\n",
    "# print(a.shape)\n",
    "# a = torch.reshape(a, (B, 1, RO, E1))\n",
    "#\n",
    "# plt.figure(figsize=(16, 16))\n",
    "# show(make_grid(a.double(), nrow=8, padding=2, normalize=False, scale_each=True))\n",
    "#\n",
    "# plt.figure(figsize=(16, 16))\n",
    "# show(make_grid(masks.double(), nrow=8, padding=2, normalize=True, scale_each=False))\n",
    "#\n",
    "# print(images.dtype)\n",
    "# X = images.type(torch.FloatTensor)\n",
    "# y = masks.type(torch.FloatTensor)\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GadgetronResUnet : F0=48, inplanes=96\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnetInputBlock : input size (48, 176, 176), output size (96, 176, 176) --> (96, 176, 176)\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnet, down layer 0:\n",
      "        GadgetronResUnet, down layer (176, 176) -> (88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "    GadgetronResUnet, down layer 1:\n",
      "        GadgetronResUnet, down layer (88, 88) -> (44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 44, 44), output size (128, 44, 44) --> (128, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 44, 44), output size (128, 44, 44) --> (128, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 44, 44), output size (128, 44, 44) --> (128, 44, 44)\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnet, bridge layer (128, 44, 44) --> (128, 44, 44)\n",
      "        GadgetronResUnet, down layer (44, 44) -> (22, 22)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 22, 22), output size (128, 22, 22) --> (128, 22, 22)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 22, 22), output size (128, 22, 22) --> (128, 22, 22)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 22, 22), output size (128, 22, 22) --> (128, 22, 22)\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnet, up layer 0:\n",
      "        GadgetronResUnet_UpSample : input size (256, 22, 22), upsampled size (256, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (256, 44, 44), output size (96, 44, 44) --> (96, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 44, 44), output size (96, 44, 44) --> (96, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 44, 44), output size (96, 44, 44) --> (96, 44, 44)\n",
      "    GadgetronResUnet, up layer 1:\n",
      "        GadgetronResUnet_UpSample : input size (192, 44, 44), upsampled size (192, 88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (192, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "    GadgetronResUnet, up layer 2:\n",
      "        GadgetronResUnet_UpSample : input size (192, 88, 88), upsampled size (192, 176, 176)\n",
      "        GadgetronResUnetBasicBlock : input size (192, 176, 176), output size (96, 176, 176) --> (96, 176, 176)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 176, 176), output size (96, 176, 176) --> (96, 176, 176)\n",
      "------------------------------------------------------------\n",
      "Output layer (96, 176, 176) --> (4, 176, 176)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from deep_learning.analysis import training\n",
    "from deep_learning.analysis.training.performance import LossMulti\n",
    "from deep_learning.analysis import models\n",
    "# import hyper_search\n",
    "# import plot_run\n",
    "# from deep_learning.analysis.training import dice_coeff, centroid_diff, adaptive_thresh\n",
    "\n",
    "num_epochs = 120\n",
    "print_every = 100000\n",
    "\n",
    "inplanes = 96\n",
    "layers=[2, 3]\n",
    "layers_planes=[96, 128]\n",
    "\n",
    "# print(perf_dataset.Gd[0].shape)\n",
    "C, H, W = (48, 176, 176)#perf_dataset.Gd[0].shape\n",
    "\n",
    "model = models.GadgetronResUnet18(F0=C, \n",
    "                                  inplanes=inplanes, \n",
    "                                  layers=layers, \n",
    "                                  layers_planes=layers_planes, \n",
    "                                  use_dropout=False, \n",
    "                                  p=0.5, \n",
    "                                  H=H, W=W, C=num_classes, # background, lv, myo, rv, rv insertion\n",
    "                                  verbose=True)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(\"model on multiple GPU ... \")\n",
    "    # print(model)\n",
    "\n",
    "patience = 5\n",
    "factor = 0.5\n",
    "cooldown = 1\n",
    "min_lr = 1e-5\n",
    "\n",
    "weight_decay=0\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=20, verbose=True)\n",
    "\n",
    "criterion = LossMulti(class_weights=class_weights, jaccard_weight=0.5)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "log_dir = 'perf_training/ResUnet' + '_lr_' + str(learning_rate) + '_epochs_' + str(num_epochs)\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# perf_trainer = training.GadgetronMultiClassSeg_Perf(model,\n",
    "#                                    optimizer,\n",
    "#                                    criterion,\n",
    "#                                    loader_for_train,\n",
    "#                                    loader_for_val,\n",
    "#                                    class_for_accu=class_for_accu,\n",
    "#                                    p_thres = p_thres,\n",
    "#                                    scheduler=scheduler,\n",
    "#                                    epochs=num_epochs,\n",
    "#                                    device=device,\n",
    "#                                    x_dtype=torch.float32,\n",
    "#                                    y_dtype=torch.long,\n",
    "#                                    early_stopping_thres = 100,\n",
    "#                                    print_every=print_every,\n",
    "#                                    small_data_mode = False,\n",
    "#                                    writer=writer,\n",
    "#                                    model_folder=\"perf_training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs_traning, epochs_validation, best_model, loss_all, epochs_acc_class = perf_trainer.train(verbose=True, epoch_to_load=-1, save_model_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc, loss, acc_class = perf_trainer.check_validation_test_accuracy(loader_for_val, best_model)\n",
    "# print(acc, loss)\n",
    "# print(acc_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     best_model_cpu = best_model.cpu().module\n",
    "# except:\n",
    "#\n",
    "#     best_model_cpu = best_model.cpu()\n",
    "#\n",
    "# print(best_model_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_dataset.transform)\n",
    "v = torch.__version__\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(perf_dataset.transform==None):\n",
    "    model_file = '/home/xueh2/mrprogs/gadgetron_CMR_ML-source/deployment/networks/perf_' + perf_dataset.which_mask + '_network_' + today + '_CMR_View' + '_Pytorch_' + v + '.pbt'\n",
    "else:\n",
    "    model_file = '/home/xueh2/mrprogs/gadgetron_CMR_ML-source/deployment/networks/perf_' + perf_dataset.which_mask + '_network_' + today + '_Pytorch_' + v  + '.pbt'\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GadgetronResUnet : F0=48, inplanes=96\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnetInputBlock : input size (48, 176, 176), output size (96, 176, 176) --> (96, 176, 176)\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnet, down layer 0:\n",
      "        GadgetronResUnet, down layer (176, 176) -> (88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "    GadgetronResUnet, down layer 1:\n",
      "        GadgetronResUnet, down layer (88, 88) -> (44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 44, 44), output size (128, 44, 44) --> (128, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 44, 44), output size (128, 44, 44) --> (128, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 44, 44), output size (128, 44, 44) --> (128, 44, 44)\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnet, bridge layer (128, 44, 44) --> (128, 44, 44)\n",
      "        GadgetronResUnet, down layer (44, 44) -> (22, 22)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 22, 22), output size (128, 22, 22) --> (128, 22, 22)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 22, 22), output size (128, 22, 22) --> (128, 22, 22)\n",
      "        GadgetronResUnetBasicBlock : input size (128, 22, 22), output size (128, 22, 22) --> (128, 22, 22)\n",
      "------------------------------------------------------------\n",
      "    GadgetronResUnet, up layer 0:\n",
      "        GadgetronResUnet_UpSample : input size (256, 22, 22), upsampled size (256, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (256, 44, 44), output size (96, 44, 44) --> (96, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 44, 44), output size (96, 44, 44) --> (96, 44, 44)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 44, 44), output size (96, 44, 44) --> (96, 44, 44)\n",
      "    GadgetronResUnet, up layer 1:\n",
      "        GadgetronResUnet_UpSample : input size (192, 44, 44), upsampled size (192, 88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (192, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 88, 88), output size (96, 88, 88) --> (96, 88, 88)\n",
      "    GadgetronResUnet, up layer 2:\n",
      "        GadgetronResUnet_UpSample : input size (192, 88, 88), upsampled size (192, 176, 176)\n",
      "        GadgetronResUnetBasicBlock : input size (192, 176, 176), output size (96, 176, 176) --> (96, 176, 176)\n",
      "        GadgetronResUnetBasicBlock : input size (96, 176, 176), output size (96, 176, 176) --> (96, 176, 176)\n",
      "------------------------------------------------------------\n",
      "Output layer (96, 176, 176) --> (4, 176, 176)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-0ac562132de3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m                                   \u001B[0mH\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mH\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mW\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mW\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mC\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m                                   verbose=True)\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m48\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m176\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m176\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;31m# empty_model.load_state_dict(best_model_wts)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Miocardium/QPerf/deep_learning/analysis/models/resunet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    312\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 314\u001B[0;31m         \u001B[0mx_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minput_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    315\u001B[0m         \u001B[0mnum_layers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Miocardium/QPerf/deep_learning/analysis/models/resunet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_dropout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    351\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    352\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 353\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    354\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight)\u001B[0m\n\u001B[1;32m    348\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m    349\u001B[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001B[0;32m--> 350\u001B[0;31m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[1;32m    351\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    352\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: conv2d(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "## Correct save!\n",
    "# import copy\n",
    "\n",
    "# best_model_wts = copy.deepcopy(best_model_cpu.cpu().state_dict())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.GadgetronResUnet18(F0=C,\n",
    "                                  inplanes=inplanes, \n",
    "                                  layers=layers, \n",
    "                                  layers_planes=layers_planes, \n",
    "                                  use_dropout=False, \n",
    "                                  p=0.5, \n",
    "                                  H=H, W=W, C=num_classes, \n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.9481e+00,  4.6973e+00,  4.4720e+00,  ..., -4.9919e+00,\n",
      "            5.3308e+00,  1.2742e+00],\n",
      "          [-6.9384e-01,  1.4164e+01,  3.7596e+00,  ...,  4.7758e+00,\n",
      "            2.5992e+00, -2.1150e-02],\n",
      "          [-3.5624e+00,  2.3591e+00,  2.2717e-01,  ...,  1.0063e+00,\n",
      "            1.3620e+01,  5.9153e+00],\n",
      "          ...,\n",
      "          [-6.7634e+00,  7.2714e+00,  3.5755e+00,  ..., -6.4128e-01,\n",
      "            8.9687e+00, -1.8707e-01],\n",
      "          [-3.9745e+00,  4.8661e+00,  5.0803e+00,  ...,  8.2429e+00,\n",
      "            1.3622e+01,  5.0748e+00],\n",
      "          [-1.5611e+00,  1.4834e+00, -6.6757e-01,  ...,  1.5673e-01,\n",
      "            6.2645e+00,  5.0092e+00]],\n",
      "\n",
      "         [[ 1.3037e+01,  9.9059e+00,  6.3939e+00,  ...,  1.1651e+01,\n",
      "            7.7376e+00,  4.0751e+00],\n",
      "          [ 1.3767e+01,  2.3246e+01,  1.3347e+01,  ...,  1.2461e+01,\n",
      "            2.2579e+01,  7.3706e+00],\n",
      "          [ 1.8052e+01,  1.6963e+01,  1.0102e+01,  ..., -1.7080e+00,\n",
      "            6.2369e+00,  1.1494e+00],\n",
      "          ...,\n",
      "          [ 1.5584e+01,  2.3638e+01,  1.8479e+01,  ...,  1.1328e+01,\n",
      "            6.5950e+00,  8.5255e-01],\n",
      "          [ 1.3734e+01,  1.9393e+01,  1.0958e+01,  ...,  1.1793e+01,\n",
      "            8.5661e+00,  1.8197e+00],\n",
      "          [ 7.7599e+00,  1.6661e+01,  9.7123e+00,  ...,  8.5677e+00,\n",
      "            7.3041e+00,  3.8546e+00]],\n",
      "\n",
      "         [[-1.3701e+00,  2.7195e-01,  4.2629e+00,  ..., -9.6590e-01,\n",
      "            6.4092e+00,  1.1860e+00],\n",
      "          [-1.2088e+00,  7.3606e+00,  1.0610e+01,  ...,  9.1602e+00,\n",
      "           -6.5622e+00,  3.2730e+00],\n",
      "          [ 7.0498e+00,  6.4167e+00,  9.8108e+00,  ...,  9.1105e+00,\n",
      "            8.8042e+00,  2.7659e+00],\n",
      "          ...,\n",
      "          [ 3.5062e+00,  9.9741e+00,  3.4748e+01,  ...,  1.3839e+01,\n",
      "            1.1763e+01,  7.6472e+00],\n",
      "          [ 6.5943e+00,  1.6923e+01,  1.1415e+01,  ...,  9.1130e+00,\n",
      "           -2.3414e+00,  5.9030e+00],\n",
      "          [-1.8439e+00,  1.6216e+00,  4.2000e+00,  ...,  4.1717e+00,\n",
      "            8.8495e-01,  6.5826e-01]],\n",
      "\n",
      "         [[ 1.8868e+00, -1.3148e+00,  3.6827e+00,  ..., -1.1705e+00,\n",
      "            1.5044e+00, -4.2365e+00],\n",
      "          [-1.0220e+01,  1.0764e+01, -2.6747e+00,  ...,  5.4762e+00,\n",
      "            4.7964e+00, -1.5040e+00],\n",
      "          [-7.2770e+00,  2.3729e+00, -3.5603e+00,  ...,  8.9550e+00,\n",
      "            7.8818e+00,  2.2684e+00],\n",
      "          ...,\n",
      "          [-2.1548e+00,  3.0269e+00,  9.7531e+00,  ...,  1.2298e+01,\n",
      "           -2.3098e+00,  1.1732e-01],\n",
      "          [-2.0628e+00,  1.3020e+01,  1.6180e+01,  ...,  1.1690e+01,\n",
      "            1.6602e+01,  9.2733e-01],\n",
      "          [ 8.3855e+00,  1.2562e+01,  1.6883e+00,  ...,  1.0466e+01,\n",
      "            3.2493e+00,  2.2523e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.6710e+00, -5.8218e-01, -9.3387e+00,  ...,  2.4181e-01,\n",
      "            3.6324e+00,  1.7163e+00],\n",
      "          [-6.4034e+00,  2.3941e+00,  6.3987e+00,  ...,  6.7540e+00,\n",
      "            8.6402e+00,  1.0747e+01],\n",
      "          [-1.2477e+01,  3.6182e+00,  6.0082e+00,  ...,  3.6984e+00,\n",
      "            1.4365e+01,  5.2546e+00],\n",
      "          ...,\n",
      "          [-1.1019e+01, -7.6711e+00,  4.4856e+00,  ..., -5.4270e+00,\n",
      "            1.8798e+00,  2.2692e+00],\n",
      "          [-8.7729e-01, -9.1862e-01,  4.5364e-01,  ..., -3.0501e+00,\n",
      "            1.2196e+01,  8.2742e+00],\n",
      "          [ 8.0674e-01,  6.3133e+00,  8.8899e+00,  ...,  1.2005e+00,\n",
      "            8.2532e+00,  3.7918e+00]],\n",
      "\n",
      "         [[ 5.7132e+00,  1.6751e+01,  1.3710e+01,  ...,  5.3331e+00,\n",
      "            9.8022e+00, -1.4242e+00],\n",
      "          [ 1.2293e+01,  1.7253e+01,  1.0742e+01,  ...,  1.5725e+01,\n",
      "            1.0676e+01,  8.9923e+00],\n",
      "          [ 1.0111e+01,  1.4722e+01,  1.2435e+01,  ...,  4.2282e+00,\n",
      "            2.1158e+00,  2.2154e+00],\n",
      "          ...,\n",
      "          [ 1.8962e+01,  1.7627e+01,  1.4396e+01,  ...,  7.6555e+00,\n",
      "            8.9249e+00,  4.6322e+00],\n",
      "          [ 1.2015e+01,  1.7915e+01,  1.5006e+01,  ...,  1.7202e-01,\n",
      "            8.1169e+00,  1.5281e+00],\n",
      "          [ 6.2621e+00,  1.4288e+01,  1.0726e+01,  ...,  1.3745e+01,\n",
      "            1.5595e+01,  5.8514e+00]],\n",
      "\n",
      "         [[ 5.3324e+00,  3.6939e+00,  9.2970e+00,  ...,  2.0123e-02,\n",
      "            3.2254e+00,  2.5732e+00],\n",
      "          [ 5.8947e+00,  2.5323e+00,  1.3858e+01,  ...,  3.9231e+00,\n",
      "            1.3252e+00,  4.9789e+00],\n",
      "          [ 5.8812e+00,  1.0439e+01,  8.9960e+00,  ...,  7.6302e+00,\n",
      "            8.2311e+00,  3.8568e+00],\n",
      "          ...,\n",
      "          [ 8.6651e+00,  1.1359e+01,  1.8312e+01,  ...,  3.7625e+00,\n",
      "            9.1065e+00,  8.2069e+00],\n",
      "          [ 6.7470e+00,  1.5842e+01,  1.8682e+01,  ...,  6.3993e+00,\n",
      "            1.3527e+01,  1.0784e+01],\n",
      "          [ 2.3244e+00, -1.7523e+00,  6.3144e+00,  ..., -2.8750e+00,\n",
      "            6.3085e+00,  4.8155e+00]],\n",
      "\n",
      "         [[-2.9028e+00,  4.6110e-01,  1.1004e+01,  ..., -1.3584e+00,\n",
      "           -4.4502e+00, -5.5416e-01],\n",
      "          [-2.1060e+00,  6.7654e+00,  1.5220e+01,  ...,  6.3917e+00,\n",
      "           -1.2299e+00, -2.7321e+00],\n",
      "          [-9.1719e-01,  8.0043e+00,  1.2507e+01,  ...,  3.2685e+00,\n",
      "           -1.1753e+00, -3.4897e+00],\n",
      "          ...,\n",
      "          [ 3.5629e+00,  7.3491e+00,  7.8165e+00,  ..., -2.4245e-02,\n",
      "           -1.9047e+00,  1.8334e+00],\n",
      "          [-5.9352e-01,  6.5258e+00,  7.2371e+00,  ...,  6.4688e+00,\n",
      "            1.0898e+01,  2.5029e+00],\n",
      "          [ 8.1987e+00,  8.8055e+00,  9.2173e+00,  ...,  1.1412e+00,\n",
      "            6.3053e+00,  1.8067e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4776e+00,  4.4257e+00,  3.5633e+00,  ...,  6.3374e+00,\n",
      "            2.4009e+00,  3.7635e+00],\n",
      "          [ 8.5616e-01, -2.3553e+00,  1.0107e+01,  ...,  5.6198e+00,\n",
      "            9.7260e+00,  4.9208e+00],\n",
      "          [-6.4181e+00,  1.2296e+01,  6.4333e+00,  ...,  1.2218e+00,\n",
      "            1.2823e+01,  1.2848e+01],\n",
      "          ...,\n",
      "          [-1.1018e+01, -8.6307e-01, -2.0500e+00,  ..., -6.9785e-01,\n",
      "            1.5002e+01, -1.7682e+00],\n",
      "          [-1.5026e+01, -6.3836e-01, -1.4376e-01,  ..., -6.5188e-01,\n",
      "            1.2486e+01,  2.1847e+00],\n",
      "          [-5.8524e+00, -4.1159e+00,  1.4120e+01,  ...,  7.0553e+00,\n",
      "            5.4947e+00,  1.6575e+00]],\n",
      "\n",
      "         [[ 1.3859e+01,  8.6970e+00,  4.4992e+00,  ...,  7.1103e+00,\n",
      "            2.4115e+00, -1.5619e+00],\n",
      "          [ 1.3423e+01,  1.7928e+01,  1.3256e+01,  ...,  1.4302e+01,\n",
      "            6.7876e+00,  3.5892e+00],\n",
      "          [ 1.6525e+01,  8.5661e+00,  9.9775e+00,  ...,  1.3436e+01,\n",
      "            9.7298e+00, -2.8742e-01],\n",
      "          ...,\n",
      "          [ 1.6769e+01,  1.8038e+01,  7.4550e+00,  ...,  6.4636e+00,\n",
      "            1.2924e+01,  1.0872e+00],\n",
      "          [ 1.3675e+01,  1.1095e+01,  1.3014e+01,  ...,  2.2033e+01,\n",
      "            1.6233e+01,  1.0739e+01],\n",
      "          [ 6.9306e+00,  2.1747e+01,  1.5923e+01,  ...,  1.4636e+01,\n",
      "            1.9340e+01,  8.9598e+00]],\n",
      "\n",
      "         [[ 2.1502e+00,  3.3142e+00,  8.2867e-01,  ...,  5.4230e+00,\n",
      "            6.0926e+00,  2.9228e+00],\n",
      "          [ 6.7984e+00,  8.7785e+00,  7.6736e+00,  ...,  3.6938e+00,\n",
      "            5.9125e+00,  8.9495e+00],\n",
      "          [-7.8844e-01,  6.0677e+00,  1.7357e+01,  ...,  1.2645e+01,\n",
      "            7.4190e+00,  1.1637e+01],\n",
      "          ...,\n",
      "          [ 5.5892e+00,  8.5707e+00,  8.5392e+00,  ...,  2.4600e+01,\n",
      "            1.3484e+01,  4.2701e+00],\n",
      "          [ 4.8870e+00,  1.7625e+01,  5.8201e+00,  ...,  8.3356e+00,\n",
      "            1.2052e+01,  7.3594e+00],\n",
      "          [ 3.7226e+00,  4.1632e+00,  7.7102e+00,  ...,  8.2540e+00,\n",
      "            3.1710e+00,  6.3614e+00]],\n",
      "\n",
      "         [[-2.7903e+00, -7.9471e+00, -5.2219e+00,  ..., -2.2844e+00,\n",
      "           -4.2165e+00, -6.8434e+00],\n",
      "          [-5.5755e+00,  1.1892e+01,  8.5803e+00,  ...,  6.4532e+00,\n",
      "            1.4877e-01,  7.7030e-01],\n",
      "          [-1.0113e+00,  6.3807e+00, -1.2423e+00,  ..., -2.2610e+00,\n",
      "           -9.7800e-01,  4.4579e+00],\n",
      "          ...,\n",
      "          [ 2.4204e+00,  5.8106e+00, -2.8631e+00,  ..., -2.7286e+00,\n",
      "            4.1770e-01, -5.6428e+00],\n",
      "          [-5.1771e+00,  1.6500e+01, -5.7053e+00,  ...,  1.5085e+01,\n",
      "            9.9982e+00,  7.0540e+00],\n",
      "          [ 1.1084e+01,  1.7420e+01,  1.6140e+01,  ...,  9.2353e+00,\n",
      "            3.8219e+00,  4.9692e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.1203e+00,  8.2812e+00,  6.0078e+00,  ..., -2.9905e+00,\n",
      "            1.9427e+00,  2.3090e+00],\n",
      "          [-5.9939e-01,  1.8495e+00,  4.6004e+00,  ..., -2.4735e+00,\n",
      "           -5.2577e+00,  3.0663e+00],\n",
      "          [-9.0797e+00,  1.3150e+01,  1.2235e+01,  ...,  2.5634e+00,\n",
      "            5.6758e+00, -6.3836e-01],\n",
      "          ...,\n",
      "          [-7.3116e+00,  2.0656e+00, -3.1766e+00,  ...,  8.3066e+00,\n",
      "            3.4299e+00,  1.0577e+00],\n",
      "          [ 1.7220e+00,  4.0629e-02,  5.2423e-01,  ...,  1.5553e+01,\n",
      "            7.2177e+00,  2.8276e+00],\n",
      "          [-4.2322e+00,  1.0402e+01,  1.2054e+00,  ...,  7.4946e+00,\n",
      "            4.6555e+00, -9.9717e-01]],\n",
      "\n",
      "         [[ 9.1056e+00,  1.3639e+01,  1.5669e+01,  ...,  1.1168e+01,\n",
      "            9.4980e+00, -4.6807e-01],\n",
      "          [ 1.7791e+01,  1.9446e+01,  1.8701e+01,  ...,  1.5833e+01,\n",
      "            1.2053e+01,  7.7615e+00],\n",
      "          [ 2.0617e+01,  7.7601e+00,  1.0491e+01,  ...,  7.6071e+00,\n",
      "           -1.9160e+00,  2.3779e+00],\n",
      "          ...,\n",
      "          [ 3.0859e+00,  1.7968e+01,  1.3534e+01,  ...,  1.6487e+01,\n",
      "            4.2880e+00,  6.0042e+00],\n",
      "          [ 5.9177e+00,  1.2446e+01,  1.1503e+01,  ...,  1.1222e+01,\n",
      "            1.4221e+01,  7.0755e+00],\n",
      "          [ 4.5095e+00,  1.3614e+01,  3.7271e+00,  ...,  7.8912e+00,\n",
      "            1.1203e+01,  3.5614e+00]],\n",
      "\n",
      "         [[-2.2348e+00,  6.7450e+00,  2.0308e+00,  ...,  1.1393e+01,\n",
      "            1.4714e+00,  4.1572e+00],\n",
      "          [-4.1655e-01,  1.0558e+01,  1.1219e+00,  ...,  1.7794e+01,\n",
      "            3.1793e+00,  1.0076e+01],\n",
      "          [-1.7881e-01,  1.6597e+01,  9.7632e+00,  ...,  1.6568e+01,\n",
      "            5.7725e+00,  4.7817e+00],\n",
      "          ...,\n",
      "          [ 4.8547e+00,  1.0782e+01,  1.4582e+01,  ...,  1.4008e+01,\n",
      "            8.0051e+00,  4.1979e+00],\n",
      "          [ 4.5693e+00,  1.5013e+01,  2.2352e+01,  ...,  1.6672e+01,\n",
      "            1.2683e+01,  7.5390e+00],\n",
      "          [-1.2084e+00,  8.2086e+00,  7.3757e+00,  ...,  2.3026e+00,\n",
      "            5.5412e-01,  4.8635e+00]],\n",
      "\n",
      "         [[-3.2053e+00,  5.7412e+00,  9.2187e+00,  ...,  1.4499e+00,\n",
      "           -2.9062e-01, -9.2392e+00],\n",
      "          [ 2.1368e-01,  2.2720e+01,  1.4118e+00,  ...,  1.2821e+01,\n",
      "            7.2910e+00, -4.9648e-01],\n",
      "          [ 3.7050e+00,  9.2481e+00, -1.9533e+00,  ...,  1.8175e+00,\n",
      "            8.7560e+00,  2.7703e+00],\n",
      "          ...,\n",
      "          [-4.4693e+00,  1.4101e+00,  2.9100e+00,  ...,  2.1742e+01,\n",
      "            8.0666e-01,  3.1527e+00],\n",
      "          [-1.3395e+00,  1.2117e+01,  1.8172e+01,  ...,  1.0838e+01,\n",
      "            8.5291e+00,  9.0869e+00],\n",
      "          [-1.5918e+00,  6.6300e+00, -2.8638e+00,  ...,  1.1660e+01,\n",
      "            7.5016e+00,  3.0969e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7930e+00,  2.6615e-01,  2.2901e+00,  ..., -5.5756e+00,\n",
      "            1.5261e-01,  4.7939e+00],\n",
      "          [-1.1436e+00,  3.9191e+00,  6.8575e+00,  ..., -7.4217e+00,\n",
      "            9.6350e+00,  8.2771e+00],\n",
      "          [ 6.4610e+00,  8.5752e-01,  3.3825e+00,  ..., -5.4810e+00,\n",
      "            6.4854e+00,  4.5452e+00],\n",
      "          ...,\n",
      "          [-4.5010e+00,  3.0589e+00,  7.7966e+00,  ...,  3.0426e+00,\n",
      "            1.1554e+01,  1.5556e+00],\n",
      "          [-6.7868e+00,  4.3455e+00,  5.6709e+00,  ...,  1.4651e+01,\n",
      "           -5.8051e+00,  1.7600e+00],\n",
      "          [-5.7801e+00,  8.5722e+00, -2.7796e+00,  ...,  5.3270e+00,\n",
      "            4.0395e+00, -2.0074e+00]],\n",
      "\n",
      "         [[ 8.0759e+00,  9.7245e+00,  1.3647e+01,  ...,  1.0685e+00,\n",
      "            3.8329e+00,  3.6732e+00],\n",
      "          [ 1.3804e+01,  2.5022e+01,  1.7507e+01,  ...,  1.5034e+01,\n",
      "            2.2972e+01,  7.3832e+00],\n",
      "          [ 2.1171e+00,  7.3420e+00, -7.5372e+00,  ...,  1.0705e+01,\n",
      "            1.2691e+01,  2.8752e+00],\n",
      "          ...,\n",
      "          [ 1.2944e+01,  1.9145e+01,  8.0261e+00,  ...,  1.4068e+01,\n",
      "            9.7163e+00,  4.4604e+00],\n",
      "          [ 8.8920e+00,  8.9250e+00, -2.8770e+00,  ...,  1.5999e+01,\n",
      "            8.3644e+00,  2.2657e+00],\n",
      "          [ 9.0240e+00,  1.4468e+01,  1.1459e+01,  ...,  1.2107e+01,\n",
      "            6.3665e+00,  6.8976e+00]],\n",
      "\n",
      "         [[ 2.2586e+00, -2.3305e+00, -8.3742e-01,  ..., -2.5385e+00,\n",
      "            1.3383e+01,  3.3018e+00],\n",
      "          [-1.6413e+00,  4.9882e+00,  3.4181e-01,  ...,  1.6896e+01,\n",
      "            8.3225e+00,  1.1461e+01],\n",
      "          [ 9.4764e+00,  8.8129e+00,  1.8680e+01,  ...,  1.3813e+01,\n",
      "            1.0614e+01,  5.9260e+00],\n",
      "          ...,\n",
      "          [ 7.3565e+00,  6.3090e+00,  2.3229e+00,  ...,  1.4216e+01,\n",
      "            1.7480e+01,  8.5881e+00],\n",
      "          [ 4.8656e+00,  1.1495e+01,  1.3989e+01,  ...,  1.3124e+01,\n",
      "            6.4320e+00,  7.2114e+00],\n",
      "          [-1.1066e+00,  1.9883e+00,  1.6794e+00,  ...,  4.0798e+00,\n",
      "            2.5306e-01,  9.5873e-01]],\n",
      "\n",
      "         [[-7.3148e-01,  5.1485e-01,  5.1737e+00,  ...,  4.2948e+00,\n",
      "            2.7262e-01, -3.1443e+00],\n",
      "          [ 1.1347e+01,  1.5735e+01,  9.2153e+00,  ...,  1.7841e+00,\n",
      "           -4.5945e+00, -5.9740e+00],\n",
      "          [ 8.9642e+00,  1.0760e+01, -1.4672e+00,  ...,  1.7679e+00,\n",
      "            5.1950e-01, -1.0780e+01],\n",
      "          ...,\n",
      "          [ 4.8791e-02,  3.1983e+00,  6.5389e-01,  ..., -9.7059e+00,\n",
      "            4.9447e+00, -8.3562e+00],\n",
      "          [ 8.8928e-01,  1.8619e+01,  8.6715e+00,  ..., -3.8772e+00,\n",
      "            1.0123e+01,  1.2485e+01],\n",
      "          [ 4.2985e+00,  8.6683e+00,  1.1084e+01,  ...,  1.6533e+01,\n",
      "            5.3099e+00,  7.6073e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0863e+00,  2.0232e+00,  1.8753e+00,  ...,  2.9500e+00,\n",
      "            2.9703e+00,  1.7247e-01],\n",
      "          [-3.7207e-01,  4.0513e+00,  7.7794e+00,  ...,  8.9846e+00,\n",
      "            6.2251e+00,  5.0295e+00],\n",
      "          [-1.3191e+00,  9.4635e+00,  6.5623e+00,  ..., -1.1961e+00,\n",
      "            6.2959e+00,  4.2124e+00],\n",
      "          ...,\n",
      "          [-2.0832e+01,  4.8300e+00,  3.5566e+00,  ..., -1.3431e+01,\n",
      "            3.4418e+00,  4.7413e+00],\n",
      "          [ 7.3468e-01,  9.1994e+00,  3.2189e+00,  ..., -5.3156e+00,\n",
      "            3.5999e+00,  1.1246e+01],\n",
      "          [ 6.0549e-01, -4.6504e+00, -1.6577e+00,  ...,  5.0907e+00,\n",
      "            7.3089e+00,  6.3857e+00]],\n",
      "\n",
      "         [[ 9.2434e+00,  1.3123e+01,  1.2758e+01,  ...,  1.4188e+01,\n",
      "            1.6701e+00,  3.4963e+00],\n",
      "          [ 1.5496e+01,  2.3245e+01,  2.6042e+01,  ...,  1.5229e+01,\n",
      "            2.4264e+01,  1.5537e+00],\n",
      "          [ 1.3815e+01,  2.5315e+01,  1.6095e+01,  ...,  5.0523e+00,\n",
      "            1.4128e+01,  3.4442e+00],\n",
      "          ...,\n",
      "          [ 1.0548e+01,  1.4841e+01,  1.2733e+01,  ...,  4.8389e+00,\n",
      "            9.7121e+00,  1.3841e+00],\n",
      "          [ 1.2625e+01,  5.3690e+00,  3.1219e-01,  ...,  4.8845e+00,\n",
      "            9.5853e+00,  1.8135e+00],\n",
      "          [ 5.0466e+00,  1.0274e+01,  1.5503e+01,  ...,  1.1398e+01,\n",
      "            7.5648e+00, -1.2701e+00]],\n",
      "\n",
      "         [[-1.0177e+00,  6.1164e+00,  2.3345e+00,  ...,  1.8881e+00,\n",
      "            6.7853e+00,  2.3555e+00],\n",
      "          [ 5.4012e-01,  2.5185e+00,  1.1872e+01,  ...,  1.1667e+00,\n",
      "           -3.0022e-01,  5.4117e+00],\n",
      "          [ 6.9824e+00,  7.8482e+00,  1.1502e+01,  ...,  9.3301e+00,\n",
      "            6.4352e+00,  5.2746e+00],\n",
      "          ...,\n",
      "          [ 9.5751e+00,  2.2280e+01,  1.4815e+01,  ...,  6.7894e+00,\n",
      "            9.1855e+00,  5.9190e+00],\n",
      "          [ 2.0916e+00,  1.1619e+01,  1.5738e+01,  ...,  1.2601e+01,\n",
      "            6.8876e+00,  8.8552e+00],\n",
      "          [-1.6524e+00,  3.2962e-01,  8.9673e+00,  ..., -7.1105e-01,\n",
      "            3.5463e+00,  2.7860e+00]],\n",
      "\n",
      "         [[-8.2607e-01,  4.8771e+00, -9.3902e+00,  ...,  3.8103e+00,\n",
      "            5.1531e-01, -2.5078e+00],\n",
      "          [ 5.9289e+00,  4.4948e+00,  1.3848e+01,  ..., -4.5231e+00,\n",
      "           -3.9660e+00,  1.6547e-01],\n",
      "          [-5.0731e-01,  1.6324e+01,  1.7770e+00,  ...,  3.3612e+00,\n",
      "            1.3061e+01, -1.6318e-01],\n",
      "          ...,\n",
      "          [-2.1840e+00,  4.8295e+00,  7.8375e+00,  ..., -3.9722e+00,\n",
      "            4.1843e+00, -6.1559e+00],\n",
      "          [ 3.5555e+00,  4.7082e+00,  8.0023e-01,  ...,  1.2805e+01,\n",
      "            1.6114e+01,  6.6708e+00],\n",
      "          [ 5.4168e+00,  1.9152e+00, -4.1340e+00,  ...,  1.1518e+01,\n",
      "            9.6089e+00,  5.1414e+00]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = np.random.normal(size=(10, 48, 176, 176))\n",
    "x_tensor = torch.Tensor(x, device=device)\n",
    "print(model(x_tensor))\n",
    "# empty_model.load_state_dict(best_model_wts)\n",
    "\n",
    "#print(empty_model)\n",
    "\n",
    "#torch.save(empty_model.state_dict(), '/home/xueh2/cmr_ml/deployment/networks/abstract_network.dict')\n",
    "# torch.save(empty_model, model_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test\n",
    "# work with python application\n",
    "# Runs on CPU so very slow\n",
    "\n",
    "# model_loaded = torch.load(model_file)\n",
    "#\n",
    "# print(model_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ff6b3c39",
   "language": "python",
   "display_name": "PyCharm (QPerf)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}